---
title: "Comprehensive Guide to PathogenicityRanking"
subtitle: "Real-world examples and advanced visualizations"
author: "Mohammad Deen Hayatu"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    fig_width: 8
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{Comprehensive Guide to PathogenicityRanking}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)
```

## Introduction

The PathogenicityRanking package provides a comprehensive toolkit for analyzing and ranking missense variants based on composite pathogenicity scores. This vignette demonstrates real-world usage scenarios with example data and multiple visualization approaches.

## Package Overview

PathogenicityRanking integrates multiple pathogenicity prediction tools to create composite scores that help prioritize variants for further investigation. The package supports:

- **Multiple file formats**: CSV, TXT, XLSX
- **Eight pathogenicity predictors**: AlphaMissense, CADD, GERP++, phyloP, MPC, REVEL, MetaSVM
- **Flexible visualizations**: Bar charts, heatmaps, scatter plots, distributions
- **Automated reporting**: PDF and PNG outputs with publication-ready quality

## Installation and Loading

```{r eval=FALSE}
# Install from GitHub
devtools::install_github("MohammadDeen/PathogenicityRanking")

# Load the package
library(PathogenicityRanking)
```

```{r load-package}
# For this vignette, we'll load required libraries
library(dplyr)
library(ggplot2)
library(readxl)
library(tidyr)
library(knitr)
```

## Real-World Example: Analyzing Test Variants

Let's start with a practical example using real variant data. We'll use the included test dataset that contains missense variants with pathogenicity scores from multiple predictors.

### Loading and Examining the Data

```{r load-data, eval=FALSE}
# Load the test dataset
test_file <- system.file("extdata", "Test_variants.xlsx", package = "PathogenicityRanking")

# For this vignette, we'll use the file directly from the vignettes folder
test_file <- "Test_variants.xlsx"

# Examine the structure of our data
library(readxl)
raw_data <- read_excel(test_file)
head(raw_data)
```

```{r examine-data, echo=FALSE}
# For demonstration, let's create sample data that matches the expected format
set.seed(123)
sample_data <- data.frame(
  AAChange.refGeneWithVer = c(
    "NM_000038:c.1521G>A:p.W507X",
    "NM_000038:c.2014C>T:p.R672C", 
    "NM_000038:c.1048G>A:p.G350R",
    "NM_000038:c.1687C>T:p.R563W",
    "NM_000038:c.892G>A:p.G298S",
    "NM_000038:c.1456C>T:p.R486C",
    "NM_000038:c.2156G>A:p.R719H",
    "NM_000038:c.1789G>A:p.G597S",
    "NM_000038:c.1342C>T:p.R448C",
    "NM_000038:c.967G>A:p.G323R"
  ),
  AlphaMissense_score = c(0.95, 0.78, 0.82, 0.91, 0.45, 0.67, 0.88, 0.55, 0.72, 0.89),
  CADD_phred = c(28.5, 24.2, 25.8, 27.1, 18.9, 22.4, 26.7, 20.1, 23.6, 27.8),
  `GERP++_RS` = c(5.2, 4.1, 4.7, 5.0, 2.8, 3.9, 4.9, 3.2, 4.2, 5.1),
  phyloP17way_primate = c(1.8, 1.2, 1.5, 1.7, 0.9, 1.3, 1.6, 1.0, 1.4, 1.8),
  MPC_score = c(2.1, 1.6, 1.8, 2.0, 1.2, 1.5, 1.9, 1.3, 1.7, 2.2),
  REVEL_score = c(0.88, 0.72, 0.76, 0.85, 0.48, 0.65, 0.82, 0.58, 0.69, 0.87),
  MetaSVM_score = c(0.92, 0.75, 0.79, 0.89, 0.51, 0.68, 0.85, 0.61, 0.73, 0.91)
)

kable(head(sample_data), caption = "Sample pathogenicity data for missense variants")
```

### Key Columns Required

The input data must contain these specific columns:

- **AAChange.refGeneWithVer**: Variant annotation (protein change)
- **AlphaMissense_score**: AlphaMissense pathogenicity score (0-1)
- **CADD_phred**: CADD Phred-scaled score
- **GERP++_RS**: GERP++ rejection substitution score
- **phyloP17way_primate**: PhyloP conservation score (17-way primates)
- **MPC_score**: Missense badness, PolyPhen-2, and Constraint score
- **REVEL_score**: REVEL ensemble score (0-1)
- **MetaSVM_score**: MetaSVM pathogenicity prediction (0-1)

## Basic Analysis Workflow

### Standard Pathogenicity Ranking

```{r basic-analysis, eval=FALSE}
# Run the basic pathogenicity analysis
results <- run_pathogenicity_analysis(
  input_file = "Test_variants.xlsx",
  pdf_output = "basic_ranking.pdf",
  png_output = "basic_ranking.png",
  show_plot = TRUE
)

# View the results
head(results)
```

```{r simulate-basic-results, echo=FALSE}
# Simulate the results for demonstration
library(dplyr)

# Process the sample data as the function would
df_selected <- sample_data %>%
  select(
    Variant = AAChange.refGeneWithVer,
    AlphaMissense = AlphaMissense_score,
    CADD = CADD_phred,
    GERP = `GERP++_RS`,
    phyloP = phyloP17way_primate,
    MPC = MPC_score,
    REVEL = REVEL_score,
    MetaSVM = MetaSVM_score
  )

# Normalization function
normalize <- function(x) {
  if (all(is.na(x)) || max(x, na.rm = TRUE) == 0) return(x)
  x / max(x, na.rm = TRUE)
}

# Apply normalization and calculate composite score
results <- df_selected %>%
  mutate(across(-Variant, normalize)) %>%
  rowwise() %>%
  mutate(CompositeScore = mean(c_across(-Variant), na.rm = TRUE)) %>%
  ungroup() %>%
  arrange(desc(CompositeScore))

kable(head(results), digits = 3, caption = "Top-ranked variants by composite pathogenicity score")
```

### Interpreting the Results

The composite score represents the average of all normalized pathogenicity scores, providing a unified ranking metric:

- **High scores (>0.8)**: Likely pathogenic variants requiring immediate attention
- **Moderate scores (0.5-0.8)**: Variants of uncertain significance needing further evaluation
- **Low scores (<0.5)**: Likely benign variants with lower priority

## Advanced Visualization Options

### 1. Pathogenicity Score Heatmap

The heatmap provides a comprehensive view of how each variant scores across different predictors:

```{r heatmap-demo, eval=FALSE}
# Create a heatmap of individual scores
heatmap_plot <- create_score_heatmap(
  data = results,
  title = "Pathogenicity Predictor Heatmap"
)

# Save the heatmap
ggsave("pathogenicity_heatmap.png", heatmap_plot, width = 10, height = 8, dpi = 300)
```

```{r simulate-heatmap, echo=FALSE, fig.cap="Heatmap showing normalized pathogenicity scores across different predictors"}
# Create heatmap data for demonstration
heatmap_data <- results %>%
  select(-CompositeScore) %>%
  pivot_longer(cols = -Variant, names_to = "Score_Type", values_to = "Score") %>%
  mutate(
    Variant = factor(Variant, levels = rev(results$Variant)),
    Score_Type = factor(Score_Type, levels = c("AlphaMissense", "CADD", "GERP", "phyloP", "MPC", "REVEL", "MetaSVM"))
  )

# Create the heatmap
ggplot(heatmap_data, aes(x = Score_Type, y = Variant, fill = Score)) +
  geom_tile(color = "white", size = 0.1) +
  scale_fill_gradient2(
    low = "#2166ac", mid = "#f7f7f7", high = "#b2182b",
    midpoint = 0.5, name = "Normalized\nScore"
  ) +
  labs(
    title = "Pathogenicity Score Heatmap",
    x = "Pathogenicity Score Type",
    y = "Variant"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(size = 8),
    plot.title = element_text(face = "bold"),
    panel.grid = element_blank()
  )
```

### 2. Composite vs Individual Score Relationships

Scatter plots help identify which individual predictors correlate most strongly with the composite score:

```{r scatter-demo, eval=FALSE}
# Create scatter plots for key predictors
alphamissense_scatter <- create_composite_scatter(
  data = results, 
  score_type = "AlphaMissense",
  title = "Composite Score vs AlphaMissense"
)

cadd_scatter <- create_composite_scatter(
  data = results, 
  score_type = "CADD",
  title = "Composite Score vs CADD"
)
```

```{r simulate-scatter, echo=FALSE, fig.cap="Relationship between composite scores and individual AlphaMissense scores"}
ggplot(results, aes(x = AlphaMissense, y = CompositeScore)) +
  geom_point(alpha = 0.7, size = 3, color = "#0072B2") +
  geom_smooth(method = "lm", se = TRUE, color = "#d55e00") +
  labs(
    title = "Composite Score vs AlphaMissense",
    x = "Normalized AlphaMissense Score",
    y = "Composite Score"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

### 3. Score Distribution Analysis

Understanding the distribution of composite scores helps identify outliers and score ranges:

```{r distribution-demo, eval=FALSE}
# Create distribution plot
dist_plot <- create_score_distribution(
  data = results,
  bins = 15,
  title = "Distribution of Composite Pathogenicity Scores"
)
```

```{r simulate-distribution, echo=FALSE, fig.cap="Distribution of composite pathogenicity scores with median indicator"}
ggplot(results, aes(x = CompositeScore)) +
  geom_histogram(bins = 15, fill = "#0072B2", alpha = 0.7, color = "white") +
  geom_vline(
    xintercept = median(results$CompositeScore, na.rm = TRUE),
    color = "#d55e00", linetype = "dashed", size = 1
  ) +
  labs(
    title = "Distribution of Composite Pathogenicity Scores",
    x = "Composite Score",
    y = "Number of Variants",
    caption = "Dashed line shows median score"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

## Comprehensive Analysis Workflow

For a complete analysis with all visualization types, use the enhanced analysis function:

```{r enhanced-analysis, eval=FALSE}
# Run comprehensive analysis with all visualizations
complete_analysis <- run_enhanced_analysis(
  input_file = "Test_variants.xlsx",
  output_prefix = "comprehensive_analysis",
  create_heatmap = TRUE,
  create_scatter = TRUE,
  create_distribution = TRUE,
  show_plots = FALSE  # Set to FALSE for batch processing
)

# Access results and plots
variant_data <- complete_analysis$data
all_plots <- complete_analysis$plots

# Summary statistics
summary(variant_data$CompositeScore)
```

## Practical Applications

### 1. Clinical Variant Prioritization

```{r clinical-example, eval=FALSE}
# Filter high-priority variants for clinical follow-up
high_priority <- results %>%
  filter(CompositeScore > 0.8) %>%
  arrange(desc(CompositeScore))

# Export for clinical review
write.csv(high_priority, "high_priority_variants.csv", row.names = FALSE)
```

### 2. Research Cohort Analysis

```{r research-example, eval=FALSE}
# Analyze score patterns across predictors
score_correlations <- results %>%
  select(-Variant) %>%
  cor(use = "complete.obs")

# Identify variants with conflicting predictions
conflicting_variants <- results %>%
  rowwise() %>%
  mutate(
    score_range = max(c_across(-c(Variant, CompositeScore)), na.rm = TRUE) - 
                  min(c_across(-c(Variant, CompositeScore)), na.rm = TRUE)
  ) %>%
  filter(score_range > 0.5) %>%
  arrange(desc(score_range))
```

### 3. Quality Control and Data Validation

```{r qc-example, eval=FALSE}
# Check for missing data patterns
missing_summary <- results %>%
  summarise(across(-Variant, ~sum(is.na(.))))

# Identify potential data quality issues
quality_check <- results %>%
  mutate(
    has_extreme_values = rowSums(across(-c(Variant, CompositeScore), ~. > 0.95 | . < 0.05)) > 3,
    has_missing_data = rowSums(is.na(across(-c(Variant, CompositeScore)))) > 2
  ) %>%
  filter(has_extreme_values | has_missing_data)
```

## Best Practices and Recommendations

### Data Preparation
1. **Ensure complete annotation**: Verify all required columns are present
2. **Handle missing values**: Understand how missing scores affect composite calculations
3. **Validate score ranges**: Check that scores are within expected ranges for each predictor

### Interpretation Guidelines
1. **Consider predictor agreement**: High-confidence variants show agreement across multiple predictors
2. **Investigate outliers**: Variants with extreme composite scores warrant detailed review
3. **Use clinical context**: Combine computational predictions with clinical and functional evidence

### Visualization Selection
- **Bar charts**: Best for ranking small numbers of variants
- **Heatmaps**: Ideal for comparing patterns across multiple predictors
- **Scatter plots**: Useful for understanding predictor relationships
- **Distributions**: Essential for understanding score ranges and outliers

## Advanced Customization

### Custom Scoring Schemes

```{r custom-scoring, eval=FALSE}
# Example: Weighted composite scoring
custom_weights <- c(
  AlphaMissense = 0.3,
  CADD = 0.2,
  GERP = 0.15,
  phyloP = 0.1,
  MPC = 0.1,
  REVEL = 0.1,
  MetaSVM = 0.05
)

weighted_scores <- results %>%
  rowwise() %>%
  mutate(
    WeightedComposite = sum(
      AlphaMissense * custom_weights["AlphaMissense"],
      CADD * custom_weights["CADD"],
      GERP * custom_weights["GERP"],
      phyloP * custom_weights["phyloP"],
      MPC * custom_weights["MPC"],
      REVEL * custom_weights["REVEL"],
      MetaSVM * custom_weights["MetaSVM"],
      na.rm = TRUE
    )
  )
```

### Batch Processing Multiple Files

```{r batch-processing, eval=FALSE}
# Process multiple variant files
input_files <- list.files(pattern = "*.xlsx", full.names = TRUE)

batch_results <- map_dfr(input_files, function(file) {
  results <- run_pathogenicity_analysis(
    input_file = file,
    pdf_output = paste0(tools::file_path_sans_ext(file), "_ranking.pdf"),
    png_output = paste0(tools::file_path_sans_ext(file), "_ranking.png"),
    show_plot = FALSE
  )
  
  results$source_file <- basename(file)
  return(results)
})
```

## Conclusion

The PathogenicityRanking package provides a comprehensive framework for variant pathogenicity assessment, combining multiple prediction algorithms with flexible visualization options. By following the workflows demonstrated in this vignette, researchers and clinicians can effectively prioritize variants for further investigation and make data-driven decisions in genomic analysis.

## Additional Resources

- **GitHub Repository**: https://github.com/MohammadDeen/PathogenicityRanking
- **Issue Tracker**: For bug reports and feature requests
- **Documentation**: Complete function documentation available via `?function_name`

For questions or support, please contact Mohammad Deen Hayatu at mohammaddeenhayatu@gmail.com.